{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bpd_evaluation.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5d1f3907d09340e697bda8d77dd31ab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_166ba8c4eff74df99bf8c8e2e0403f7f",
              "IPY_MODEL_35035ac0c4df4688bc79ee902f87a46f",
              "IPY_MODEL_05b5258924b44806bfdb2d879a401506"
            ],
            "layout": "IPY_MODEL_d5a31ae2e5ff40c29f54e8c83597b6ab"
          }
        },
        "166ba8c4eff74df99bf8c8e2e0403f7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d5972ab1a064050a5a977e52e7b8c71",
            "placeholder": "​",
            "style": "IPY_MODEL_cfa809fad40440d5816489e782278ed2",
            "value": "100%"
          }
        },
        "35035ac0c4df4688bc79ee902f87a46f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67ee1c9c2b55483b859371ffbde5ed1f",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_20752e2f3f184edfb3cbaa73305cd10e",
            "value": 170498071
          }
        },
        "05b5258924b44806bfdb2d879a401506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_500aef6621fc4ab68fb3813d3a21a44d",
            "placeholder": "​",
            "style": "IPY_MODEL_2c5a442d040b42d4b1135fc039a24f0b",
            "value": " 170498071/170498071 [00:04&lt;00:00, 45953609.47it/s]"
          }
        },
        "d5a31ae2e5ff40c29f54e8c83597b6ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d5972ab1a064050a5a977e52e7b8c71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfa809fad40440d5816489e782278ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67ee1c9c2b55483b859371ffbde5ed1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20752e2f3f184edfb3cbaa73305cd10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "500aef6621fc4ab68fb3813d3a21a44d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c5a442d040b42d4b1135fc039a24f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "t8NVExKENvhn"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "import math\n",
        "import os\n",
        "import argparse\n",
        "\n",
        "\n",
        "def update_ema(ema_model, model, ema_rate):\n",
        "    for tar, src in zip(ema_model.parameters(), model.parameters()):\n",
        "        tar.data.mul_(ema_rate).add_(src.data * (1 - ema_rate))\n",
        "\n",
        "\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.cnt = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.sum += val * n\n",
        "        self.cnt += n\n",
        "        self.avg = self.sum / self.cnt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_transform = transforms.Compose([transforms.RandomHorizontalFlip(), transforms.ToTensor()])\n",
        "test_transform = transforms.Compose([transforms.ToTensor()])\n",
        "train_dataset = datasets.CIFAR10(root='../data', train=True, download=True, transform=train_transform)\n",
        "test_dataset = datasets.CIFAR10(root='../data', train=False, download=True, transform=test_transform)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105,
          "referenced_widgets": [
            "5d1f3907d09340e697bda8d77dd31ab3",
            "166ba8c4eff74df99bf8c8e2e0403f7f",
            "35035ac0c4df4688bc79ee902f87a46f",
            "05b5258924b44806bfdb2d879a401506",
            "d5a31ae2e5ff40c29f54e8c83597b6ab",
            "5d5972ab1a064050a5a977e52e7b8c71",
            "cfa809fad40440d5816489e782278ed2",
            "67ee1c9c2b55483b859371ffbde5ed1f",
            "20752e2f3f184edfb3cbaa73305cd10e",
            "500aef6621fc4ab68fb3813d3a21a44d",
            "2c5a442d040b42d4b1135fc039a24f0b"
          ]
        },
        "id": "a84Yh3BtNxm5",
        "outputId": "3c4d55d8-35ca-4390-95c5-7edfaac372de"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5d1f3907d09340e697bda8d77dd31ab3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/cifar-10-python.tar.gz to ../data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GaussianFourierProjection(nn.Module):\n",
        "    def __init__(self, embed_dim, init_scale=1., learnable=False):\n",
        "        super().__init__()\n",
        "        self.emb = init_scale * torch.randn(embed_dim // 2)\n",
        "        self.emb = nn.Parameter(self.emb, requires_grad=learnable)\n",
        "    \n",
        "    def forward(self, t):\n",
        "        t = 2. * np.pi * t[:, None] * self.emb[None, :]\n",
        "        return torch.cat([torch.sin(t), torch.cos(t)], dim=-1)\n",
        "\n",
        "\n",
        "class PositionalEmbedding(nn.Module):\n",
        "    def __init__(self, embed_dim, max_positions=10000):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.max_positions = max_positions \n",
        "        self.half_dim = embed_dim // 2\n",
        "        self.emb = math.log(max_positions) / (self.half_dim - 1)\n",
        "        self.emb = torch.exp(torch.arange(self.half_dim).float() * -self.emb)\n",
        "        self.emb = nn.Parameter(self.emb, requires_grad=False)\n",
        "\n",
        "    def forward(self, t):\n",
        "        t = 0.9 * self.max_positions * t[:, None] * self.emb[None, :]\n",
        "        return torch.cat([torch.sin(t), torch.cos(t)], dim=-1)"
      ],
      "metadata": {
        "id": "lTLYRVWwNzfq"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Upsize(nn.Module):\n",
        "    def __init__(self, cin, cout=None):\n",
        "        super().__init__()\n",
        "        cout = cin if cout is None else cout\n",
        "        self.conv = nn.Conv2d(cin, cout, 3, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.interpolate(x, scale_factor=2.0, mode=\"nearest\")\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Downsize(nn.Module):\n",
        "    def __init__(self, cin, cout=None):\n",
        "        super().__init__()\n",
        "        cout = cin if cout is None else cout\n",
        "        self.conv = nn.Conv2d(cin, cout, 3, 2, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.pad(x, (0, 1, 0, 1), mode=\"constant\", value=0)\n",
        "        x = self.conv(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "MaemW1L0Nzmx"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_signal_scale(log_snr):\n",
        "    return torch.sigmoid(log_snr).sqrt()\n",
        "\n",
        "def get_noise_scale(log_snr):\n",
        "    return torch.sigmoid(-log_snr).sqrt()\n",
        "\n",
        "\n",
        "class LinearLogSnrDiffuser(object):\n",
        "    def __init__(self):\n",
        "        self.min_time = 1e-5\n",
        "        self.log_snr0 = np.log(1 / (np.exp(1e-4) - 1))\n",
        "        self.log_snr1 = np.log(1 / (np.exp(1e-4 + 10) - 1))\n",
        "\n",
        "    def sample_time(self, batch_size):\n",
        "        return self.min_time + torch.rand(batch_size) * (1. - self.min_time)\n",
        "\n",
        "    def log_snr(self, t):\n",
        "        return self.log_snr0 + (self.log_snr1 - self.log_snr0) * t\n",
        "    \n",
        "    def forward_process(self, x, t, noise=None):\n",
        "        noise = torch.randn_like(x) if noise is None else noise\n",
        "        log_snr = self.log_snr(t).unflatten(-1, (-1, *[1 for _ in x.size()[1:]]))\n",
        "        alpha = get_signal_scale(log_snr)\n",
        "        sigma = get_noise_scale(log_snr)\n",
        "        return alpha * x + sigma * noise, noise\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def reverse_process(self, z, model, num_steps):\n",
        "        time = torch.ones(z.size()[0]).to(z.device)\n",
        "        reversed_time = torch.linspace(1., 0., num_steps + 1)\n",
        "        dt = reversed_time[0] - reversed_time[1]\n",
        "        for i in range(num_steps): # t -> s\n",
        "            t = reversed_time[i]        \n",
        "            s = reversed_time[i + 1]\n",
        "            log_snr_s = self.log_snr(s)\n",
        "            log_snr_t = self.log_snr(t)\n",
        "            alpha_s = get_signal_scale(log_snr_s)\n",
        "            sigma_s = get_noise_scale(log_snr_s)\n",
        "            alpha_t = get_signal_scale(log_snr_t)\n",
        "            sigma_t = get_noise_scale(log_snr_t)\n",
        "            alpha_s_to_t = alpha_t / alpha_s\n",
        "            sigma_s_to_t = torch.sqrt(sigma_t.square() - alpha_s_to_t.square() * sigma_s.square())\n",
        "            sigma_t_to_s = torch.sqrt(sigma_s.square() * sigma_s_to_t.square() / sigma_t.square())\n",
        "            prev_coeff = 1 / alpha_s_to_t\n",
        "            noise_coeff = - sigma_s_to_t.square() / (alpha_s_to_t * sigma_t)\n",
        "\n",
        "            time.fill_(t)\n",
        "            noise_pred = model(z, time)\n",
        "            z = prev_coeff * z + noise_coeff * noise_pred + torch.randn_like(z) * sigma_t_to_s\n",
        "            x_pred = (z - sigma_s * noise_pred) / alpha_s\n",
        "\n",
        "        return x_pred"
      ],
      "metadata": {
        "id": "gu7JwheGN1vx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Resnet(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, num_groups=8, time_dim=None, dropout_ratio=0.05, bottleneck_ratio=0.5):\n",
        "        super().__init__()\n",
        "        cmid = int(bottleneck_ratio * in_ch)\n",
        "        self.res_in = nn.Sequential(nn.GroupNorm(num_groups, in_ch),\n",
        "                                    nn.SiLU(inplace=True),\n",
        "                                    nn.Conv2d(in_ch, cmid, 3, 1, 1))\n",
        "\n",
        "        self.time = nn.Linear(time_dim, cmid) if time_dim is not None else None\n",
        "\n",
        "        self.res_out = nn.Sequential(nn.GroupNorm(num_groups, num_channels=cmid),\n",
        "                                     nn.SiLU(inplace=True),\n",
        "                                     nn.Dropout(p=dropout_ratio),\n",
        "                                     nn.Conv2d(cmid, out_ch, 3, 1, 1))\n",
        "\n",
        "        self.skip = None if in_ch == out_ch else nn.Conv2d(in_ch, out_ch, 1, 1, 0)\n",
        "\n",
        "    def forward(self, x, t=None):\n",
        "        res = self.res_in(x)\n",
        "        if t is not None:\n",
        "            time = self.time(t).unflatten(-1, (-1, 1, 1))\n",
        "            res = res + time\n",
        "        \n",
        "        res = self.res_out(res)\n",
        "        return x + res if self.skip is None else self.skip(x) + res"
      ],
      "metadata": {
        "id": "wmZmABrwN1yQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(nn.Module):\n",
        "    def __init__(self, channels, num_heads=4, num_groups=8, bottleneck_ratio=0.5):\n",
        "        super().__init__()\n",
        "        self.hidden_size = int(bottleneck_ratio * channels)\n",
        "        self.channels, self.num_heads = channels, num_heads\n",
        "        self.group_norm = nn.GroupNorm(num_groups, channels)\n",
        "        self.proj = nn.Conv2d(channels, 3 * self.hidden_size, 1, 1, 0, bias=False)\n",
        "        self.out = nn.Conv2d(self.hidden_size, channels, 1, 1, 0)\n",
        "        self.scale = (self.hidden_size // self.num_heads) ** -0.5\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.group_norm(x)\n",
        "        q, k, v = self.proj(h).flatten(-2, -1).unflatten(1, (self.num_heads * 3, -1)).chunk(3, dim=1)\n",
        "        w = torch.matmul(q.transpose(-2, -1), k * self.scale)\n",
        "        h = torch.matmul(v, w.softmax(dim=-2)).unflatten(-1, x.size()[2:]).flatten(1, 2)\n",
        "        return x + self.out(h)"
      ],
      "metadata": {
        "id": "sk5axVkSN10r"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, args):\n",
        "        super().__init__()\n",
        "\n",
        "        self.channels = args.arch.channels\n",
        "        self.time_dim = args.arch.time_dim\n",
        "\n",
        "        self.input_conv = [nn.Conv2d(args.arch.input_channels, self.channels, 3, 1, padding='same'),\n",
        "                           nn.SiLU()]\n",
        "\n",
        "        self.input_conv = nn.Sequential(*self.input_conv)\n",
        "        \n",
        "        self.time_embed = [PositionalEmbedding(self.channels),\n",
        "                           nn.Linear(self.channels, self.time_dim), \n",
        "                           nn.SiLU(inplace=True), \n",
        "                           nn.Linear(self.time_dim, self.time_dim),\n",
        "                           nn.SiLU()]\n",
        "\n",
        "        self.time_embed = nn.Sequential(*self.time_embed)\n",
        "\n",
        "        self.enc_tower = []\n",
        "\n",
        "        for l, n_layers in enumerate(args.arch.n_layers):\n",
        "            in_ch = self.channels if l == 0 else args.arch.ch_mults[l - 1] * self.channels\n",
        "            ch = args.arch.ch_mults[l] * self.channels\n",
        "            block = Downsize(in_ch, ch) if args.arch.resample[l] else nn.Conv2d(in_ch, ch, 1, 1, 0)\n",
        "            self.enc_tower += [block]\n",
        "\n",
        "            for _ in range(n_layers):\n",
        "                self.enc_tower += [Resnet(ch, ch, time_dim=self.time_dim)]\n",
        "                self.enc_tower += [Attention(ch)] if args.arch.use_attn[l] else []\n",
        "\n",
        "        self.enc_tower = nn.ModuleList(self.enc_tower)\n",
        "        mid_ch = args.arch.ch_mults[-1] * self.channels\n",
        "        self.mid1 = Resnet(mid_ch, mid_ch, time_dim=self.time_dim)\n",
        "        self.mid2 = Attention(mid_ch, bottleneck_ratio=0.25)\n",
        "        self.mid3 = Resnet(mid_ch, mid_ch, time_dim=self.time_dim)\n",
        "\n",
        "        self.dec_tower = []\n",
        "        for l, mult in list(enumerate(args.arch.n_layers))[::-1]:\n",
        "            \n",
        "            ch = args.arch.ch_mults[l] * self.channels\n",
        "            out_ch = self.channels if l == 0 else args.arch.ch_mults[l - 1] * self.channels\n",
        "\n",
        "            for _ in range(n_layers):\n",
        "                self.dec_tower += [Attention(ch)] if args.arch.use_attn[l] else []\n",
        "                self.dec_tower += [Resnet(2 * ch, ch, time_dim=self.time_dim)]\n",
        "\n",
        "            block = Upsize(ch, out_ch) if args.arch.resample[l] else nn.Conv2d(ch, out_ch, 1, 1, 0)\n",
        "            self.dec_tower += [block]\n",
        "        \n",
        "        self.dec_tower = nn.ModuleList(self.dec_tower)\n",
        "        self.output_conv = [nn.SiLU(),\n",
        "                            nn.Conv2d(self.channels, args.arch.output_channels, 1, 1, 0)]\n",
        "\n",
        "        self.output_conv = nn.Sequential(*self.output_conv)\n",
        "\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        x = self.input_conv(x)\n",
        "        t = self.time_embed(t)\n",
        "        u = []\n",
        "        for enc in self.enc_tower:\n",
        "            if isinstance(enc, Resnet):\n",
        "                x = enc(x, t)\n",
        "                u.append(x)\n",
        "            else:\n",
        "                x = enc(x)\n",
        "\n",
        "        x = self.mid1(x, t)\n",
        "        x = self.mid2(x)\n",
        "        x = self.mid3(x, t)\n",
        "\n",
        "        for dec in self.dec_tower:\n",
        "            if isinstance(dec, Resnet):\n",
        "                x = torch.cat([x, u.pop()], dim=1)\n",
        "                x = dec(x, t)\n",
        "            else:\n",
        "                x = dec(x)\n",
        "\n",
        "        x = self.output_conv(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "fyg3OKWFN13N"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args = argparse.Namespace()\n",
        "args.arch = argparse.Namespace()\n",
        "args.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "args.batch_size = 64\n",
        "args.learning_rate = 1e-4\n",
        "args.num_epochs = 100\n",
        "args.ema_rate = 0.9999\n",
        "\n",
        "args.arch.input_channels = 3\n",
        "args.arch.output_channels = 3\n",
        "args.arch.channels = 128\n",
        "args.arch.time_dim = args.arch.channels * 4\n",
        "args.arch.ch_mults = [1, 2, 4, 8]\n",
        "args.arch.n_layers = [4, 4, 4, 4]\n",
        "args.arch.use_attn = [False, False,  True, False]\n",
        "args.arch.resample = [False,  True,  True,  True]\n",
        "\n",
        "model = UNet(args).to(args.device)\n",
        "ema_model = copy.deepcopy(model)\n",
        "\n",
        "ema_model.requires_grad_(False)\n",
        "diffuser = LinearLogSnrDiffuser()\n",
        "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate)\n",
        "loss_meter = AverageMeter()"
      ],
      "metadata": {
        "id": "H06SkZ18N15X"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load(\"/content/drive/My Drive/\" + \"vdm_cifar10.pth\")\n",
        "model.load_state_dict(state_dict['model'])\n",
        "optimizer.load_state_dict(state_dict['optimizer'])\n",
        "ema_model.load_state_dict(state_dict['ema_model'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QmLkqLpN_gy",
        "outputId": "4bc982d4-d4ef-440a-c8fc-570891c1aa9b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "\n",
        "def evaluate_bpd(data, model, num_steps, scheduler):\n",
        "    time = torch.ones(data.size()[0]).to(data.device)\n",
        "    reversed_time = torch.linspace(1., 0., num_steps + 1)\n",
        "    dt = reversed_time[0] - reversed_time[1]\n",
        "\n",
        "\n",
        "    elbo = 0.\n",
        "\n",
        "    # z = torch.randn_like(data)\n",
        "\n",
        "    for i in range(num_steps): # t -> s\n",
        "        t = reversed_time[i]        \n",
        "        s = reversed_time[i + 1]\n",
        "        log_snr_s = scheduler.log_snr(s)\n",
        "        log_snr_t = scheduler.log_snr(t)\n",
        "        alpha_s = get_signal_scale(log_snr_s)\n",
        "        sigma_s = get_noise_scale(log_snr_s)\n",
        "        alpha_t = get_signal_scale(log_snr_t)\n",
        "        sigma_t = get_noise_scale(log_snr_t)\n",
        "        alpha_s_to_t = alpha_t / alpha_s\n",
        "        sigma_s_to_t = torch.sqrt(sigma_t.square() - alpha_s_to_t.square() * sigma_s.square())\n",
        "        sigma_t_to_s = torch.sqrt(sigma_s.square() * sigma_s_to_t.square() / sigma_t.square())\n",
        "        \n",
        "        z = alpha_t * data + sigma_t * torch.randn_like(data)\n",
        "        true_mu = ((alpha_s_to_t / sigma_s_to_t.square()) * z + (alpha_s / sigma_s.square()) * data) * sigma_t_to_s.square()\n",
        "\n",
        "        time.fill_(t)\n",
        "        noise_pred = model(z, time)\n",
        "        pred_x0 = x_pred = (z - sigma_t * noise_pred) / alpha_t\n",
        "        pred_mu = ((alpha_s_to_t / sigma_s_to_t.square()) * z + (alpha_s / sigma_s.square()) * pred_x0) * sigma_t_to_s.square()\n",
        "\n",
        "        if i != num_steps - 1:\n",
        "            kld = 0.5 * (true_mu - pred_mu).square().mean(dim=0).sum() / sigma_t_to_s.square()\n",
        "            elbo += kld\n",
        "            # z = true_mu + sigma_t_to_s * torch.randn_like(data)\n",
        "        \n",
        "        else:\n",
        "            log_prob = - 0.5 * (data - pred_mu).square().mean(dim=0).sum() / sigma_t_to_s.square()\n",
        "            log_prob = log_prob - 0.5 * torch.log(np.sqrt(2. * np.pi) * sigma_t_to_s)\n",
        "            elbo -= log_prob  \n",
        "\n",
        "    bpd = elbo / (3 * 32 * 32 * np.log(2))\n",
        "    return bpd\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMl9rzZOmw84",
        "outputId": "e3108350-39d3-4bf3-9c1f-a70e85e3191c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.3233, device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
        "\n",
        "ema_model.eval()\n",
        "avg_bpd = AverageMeter()\n",
        "for x, _ in loader:\n",
        "    x = x.to(args.device)\n",
        "    x = 2. * x - 1.\n",
        "    bpd = evaluate_bpd(x, ema_model, 25, diffuser)\n",
        "    avg_bpd.update(bpd.item())\n",
        "\n",
        "print(avg_bpd.avg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCxhZ5R_0FOb",
        "outputId": "489fed06-be2d-4952-c1ce-83074f18034c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.2841094566296927\n"
          ]
        }
      ]
    }
  ]
}